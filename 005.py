Tuning models with cross-validation

We will use the split() method from the StratifiedKFold class of scikit-learn to
divide the data into chunks with preserved class distribution:
>>> from sklearn.model_selection import StratifiedKFold
>>> k = 5
>>> k_fold = StratifiedKFold(n_splits=k, random_state=42)




We start with the following options:
>>> smoothing_factor_option = [1, 2, 3, 4, 5, 6]
>>> fit_prior_option = [True, False]
>>> auc_record = {}



Then, for each fold generated by the split() method of the k_fold object, we
repeat the process of classifier initialization, training, and prediction with one of the
aforementioned combinations of parameters, and record the resulting AUCs:
>>> for train_indices, test_indices in k_fold.split(X, Y):
... X_train, X_test = X[train_indices], X[test_indices]
... Y_train, Y_test = Y[train_indices], Y[test_indices]
... for alpha in smoothing_factor_option:
... if alpha not in auc_record:
... auc_record[alpha] = {}
... for fit_prior in fit_prior_option:
... clf = MultinomialNB(alpha=alpha,
... fit_prior=fit_prior)
... clf.fit(X_train, Y_train)
... prediction_prob = clf.predict_proba(X_test)
... pos_prob = prediction_prob[:, 1]
... auc = roc_auc_score(Y_test, pos_prob)
... auc_record[alpha][fit_prior] = auc +
... auc_record[alpha].get(fit_prior, 0.0)





Finally, we present the results, as follows:
>>> for smoothing, smoothing_record in auc_record.items():
... for fit_prior, auc in smoothing_record.items():
... print(f' {smoothing} {fit_prior}
... {auc/k:.5f}')
smoothing fit prior auc
1 True 0.65647
1 False 0.65708
2 True 0.65795
2 False 0.65823
[ 73 ]
3 True 0.65740
3 False 0.65801
4 True 0.65808
4 False 0.65795
5 True 0.65814
5 False 0.65694
6 True 0.65663
6 False 0.65719






The (2, False) set enables the best averaged AUC, at 0.65823.
Finally, we retrain the model with the best set of hyperparameters (2, False) and
compute the AUC:
>>> clf = MultinomialNB(alpha=2.0, fit_prior=False)
>>> clf.fit(X_train, Y_train)
>>> pos_prob = clf.predict_proba(X_test)[:, 1]
>>> print('AUC with the best model:', roc_auc_score(Y_test,
... pos_prob))
AUC with the best model: 0.6862056720417091